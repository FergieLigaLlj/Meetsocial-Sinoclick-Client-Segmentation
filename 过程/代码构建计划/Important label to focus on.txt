Important numeric label to focus on:
1. month_avg_spendaccount_num
2. month_avg_ad_count
3. month_avg_spend_amt
4. d91_plus_spend_usd
5. ratio_avg_daily_spend_max_to_first
6. ratio_avg_daily_spend_max_to_last
7. avg_monthly_active_days
8. month_avg_custom_region_count
9. consumed_level3_category_count
好的，我们接下来对K = 3，Kmeans聚类模型做“numeric数值型+descriptive描述型”的最终客群画像描述型文档输出。这个底层逻辑是分别在数值型的原始表格和描述型的原始表格里按照我给出以下对每个字段的指示算出我所需要的每一字段的数据：
数值型的原始表格：逻辑：df_k3_kmeans_all_raw.csv中所有的字段排除df_k3_kmeans_descriptive.csv里的所有字段；描述型的原始表格：逻辑：df_k3_kmeans_descriptive.csv里的所有字段。
数值型的表格里需要取数的字段：
1. month_avg_spendaccount_num：双尾95%的置信区间，平均值。
2. month_avg_ad_count：双尾95%的置信区间，平均值。
3. business_background：不是大量Unknown里占比最高的top2的两类，以及这两类的占比。
4. first_7d_spend_usd：双尾95%的置信区间，平均值。
5. value_concentration_index_daily：双尾95%的置信区间，平均值。
6. onboarding_intent_tier：双尾95%的置信区间，平均值。
7. month_avg_spend_amt：双尾95%的置信区间，平均值。
8. avg_monthly_active_days：双尾95%的置信区间，平均值。
9. consumed_level3_category_count：双尾95%的置信区间，平均值。
10. days_since_last_spend：双尾95%的置信区间，平均值。
11. is_core_category_clothing：1的占比。
12. is_core_category_accessories：1的占比。
13. is_core_category_beauty：1的占比。
14. is_core_category_electronics：1的占比。
15.has_high_risk_flag_real_money,has_high_risk_flag_counterfeit,has_high_risk_flag_cheat,has_high_risk_flag_gambling这四个risk里全量计算：最终1的占比。
描述型的原始表格里需要取数的字段：
1. top_l2_category：最多的三个。
2. top_l2_l3_combined：最多的三个。
3. top_custom_region_all：最多的三个。
4. main_regions：按照中间的'_'再拆开来，找出最多的三个。
5. corporation_promotion_channel_second：渠道最多的5个。
6. main_media: 最多的2个。
按照这个字段cluster_kmeans_k3的分群。
输出：慢慢来，严格的*执行上述计划*，严谨地通过Python代码算出所有的字段需要的数值和类型。需要非常高质量的客群画像。
#Think#Python#Calculate







我的发现：‘Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...’。我的理解是我们这种输出方法并不能直观完整地展现所有数据和对比的效果。
我建议你保证取数逻辑和代码完全不变的情况下，用pd里面的表格输出成一个外置的表格文件，这样看的更清楚一些，每一列就是0，1，2三个群。
#Think#Python#表格